{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agawronski/word-embeddings/blob/main/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3gjJ-w_H7Zb"
      },
      "outputs": [],
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS, strip_tags\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.mofrom gensim.models \n",
        "import CoherenceModeldels.ldamodel import LdaModel\n",
        "from gensim import matutils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import defaultdict\n",
        "from gensim.parsing.preprocessing import preprocess_string\n",
        "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
        "from gensim.parsing.preprocessing import STOPWORDS, strip_tags,strip_numeric, remove_stopwords,strip_short, stem_text\n",
        "from gensim.models import Phrases\n",
        "from gensim import corpora, models, similarities\n",
        "import nltk\n",
        "import heapq \n",
        "import os\n",
        "import json\n",
        "# Lemmatize the documents.\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import lda\n",
        "from gensim.models import Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gobtnbih_Ip"
      },
      "outputs": [],
      "source": [
        "https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS5ympCbNfV-",
        "outputId": "10212dce-624f-4792-f298-1abda18d8379"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\FLORENCIA\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVCOUMfMN5BF",
        "outputId": "cc5a35b7-9459-4b5c-c5a5-3b3994d00e93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\FLORENCIA\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kS6FGd-h_Ir"
      },
      "source": [
        "### 1. Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "bo8AhQLQLQNY",
        "outputId": "681936af-d8a1-4a70-de1b-e8be262e377e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Avian influenza is an acute viral respiratory ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Managing what Cannot be Managed On the Possibi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>References Aaron HJ, “How Not to Reform Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Porcine epidemic diarrhea (PED) was first reco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>APPENDIX B Federal Geospatial Data Sources Ide...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             article\n",
              "0  Avian influenza is an acute viral respiratory ...\n",
              "1  Managing what Cannot be Managed On the Possibi...\n",
              "2  References Aaron HJ, “How Not to Reform Medica...\n",
              "3  Porcine epidemic diarrhea (PED) was first reco...\n",
              "4  APPENDIX B Federal Geospatial Data Sources Ide..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/GLG project/data')\n",
        "\n",
        "with open('healthcare_industry_from_1900_2021.jsonl') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "corpus = [json.loads(line)['fullText'] for line in lines ] \n",
        "corpus = [' '.join(text)  for text in corpus]\n",
        "df = pd.DataFrame(corpus, columns=['article' ])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUaJJN8cMsif"
      },
      "source": [
        "### 2. Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1FXVNibh_Iu"
      },
      "source": [
        "Remove digits, transform to lowercase, remove stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn797LmhH7Z0"
      },
      "source": [
        "We find bigrams in the documents. Bigrams are sets of two adjacent words. Using bigrams we can get phrases like “machine_learning” in our output (spaces are replaced with underscores); without bigrams we would only get “machine” and “learning”.\n",
        "\n",
        "Note that in the code below, we find bigrams and then add them to the original data, because we would like to keep the words “machine” and “learning” as well as the bigram “machine_learning”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUvivvWwh_Iv"
      },
      "outputs": [],
      "source": [
        "def preprocessing(corpus):\n",
        "    custom_filters=[lambda x:x.lower(), \n",
        "                    strip_multiple_whitespaces,\n",
        "                    strip_numeric, #Remove digits from s using RE_NUMERIC.\n",
        "                    remove_stopwords]\n",
        "    tokenized_docs = [preprocess_string(doc, custom_filters) for doc in corpus]\n",
        "    stop_words=set(stopwords.words(\"english\"))\n",
        "    tokenized_docs = [[token for token in text if token not in stop_words] for text in tokenized_docs]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokenized_docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in tokenized_docs]\n",
        "    bigram = Phrases(tokenized_docs, min_count=2)\n",
        "    for idx in range(len(tokenized_docs)):\n",
        "        for token in bigram[tokenized_docs[idx]]:\n",
        "            if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "                tokenized_docs[idx].append(token)\n",
        "    trigram = Phrases(bigram[tokenized_docs], min_count=2)\n",
        "    for idx in range(len(tokenized_docs)):\n",
        "        for token in trigram[tokenized_docs[idx]]:\n",
        "            if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "                tokenized_docs[idx].append(token)\n",
        "    return tokenized_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAqVxMjdh_Iw"
      },
      "outputs": [],
      "source": [
        "tokenized_docs=preprocessing(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGffQYGYh_Iw"
      },
      "source": [
        "### 3. Exploratory Analysis\n",
        "We’ll make a word cloud using the wordcloud package to get a visual representation of most common words. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obDYHAuUh_Ix"
      },
      "outputs": [],
      "source": [
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in tokenized_docs:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than one\n",
        "tokenized_docs = [[token for token in text if frequency[token] > 1] for text in tokenized_docs]\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist()\n",
        "for text in tokenized_docs:\n",
        "    for token in text:\n",
        "        fdist[token.lower()] += 1\n",
        "        \n",
        "\n",
        "# Frequency Distribution Plot\n",
        "import matplotlib.pyplot as plt\n",
        "fdist.plot(30,cumulative=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-x2RUWIh_Iy"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "def show_wordcloud(data, title = None):\n",
        "       wordcloud = WordCloud(\n",
        "           background_color='white',\n",
        "           stopwords=stopwords,\n",
        "           max_words=100, #mask=arg_mask, contour_width=3, contour_color='steelblue',\n",
        "           max_font_size=40, min_font_size=6,\n",
        "           scale=3,relative_scaling=1,\n",
        "           random_state=1 # chosen at random by flipping a coin; it was heads\n",
        "       ).generate_from_frequencies(data)\n",
        "\n",
        "       fig = plt.figure(1, figsize=(12, 12))\n",
        "       plt.axis('off')\n",
        "       if title: \n",
        "           fig.suptitle(title, fontsize=20)\n",
        "           fig.subplots_adjust(top=2.3)\n",
        "\n",
        "       plt.imshow(wordcloud)\n",
        "       plt.show()\n",
        "        \n",
        "show_wordcloud(fdist, title = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPM5GORhOYKJ"
      },
      "source": [
        "### 4. Prepare data for LDA Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x_y_D3nH7Z3"
      },
      "outputs": [],
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(tokenized_docs)\n",
        "print(id2word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoimIiTkH7Z3"
      },
      "source": [
        "We remove rare words and common words based on their document frequency. \n",
        "Below we remove words that appear in less than 20 documents or in more than 50% of the documents. Consider trying to remove words only based on their frequency, or maybe combining that with this approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2vI1xf0H7Z4"
      },
      "outputs": [],
      "source": [
        "# Filter out words that occur more than 80% of the documents.\n",
        "id2word.filter_extremes(no_above=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Beo9k-nkH7Z4"
      },
      "outputs": [],
      "source": [
        "#covert tokenized documnent to vectors Term Document Frequency\n",
        "corpus_2=[id2word.doc2bow(text) for text in tokenized_docs]\n",
        "# Create Corpus\n",
        "texts = tokenized_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93quhiagH7Z5",
        "outputId": "888d42c3-36fb-43f2-f315-8f56be8e0dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique tokens: 100000\n",
            "Number of documents: 1500\n"
          ]
        }
      ],
      "source": [
        "print('Number of unique tokens: %d' % len(id2word))\n",
        "print('Number of documents: %d' % len(texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9hl-8aqH7Z6"
      },
      "source": [
        "### 5. Build LDA model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAEVMrXeh_I0"
      },
      "source": [
        "We’ll keep all the parameters to default except for inputting the number of topics. \n",
        "we will build a model with 10 topics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk90NiRNQdFK"
      },
      "outputs": [],
      "source": [
        "#number of topics\n",
        "num_topics = 10\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus_2,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=num_topics, \n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66iEOCi9RPwo",
        "outputId": "d26da6f0-d67e-4702-f1d1-6c173156d6bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.011*\"woman\" + 0.003*\"women’s\" + 0.003*\"book\" + 0.003*\"like\" + '\n",
            "  '0.003*\"new_york\" + 0.003*\"feminist\" + 0.003*\"lesbian\" + 0.003*\"black\" + '\n",
            "  '0.002*\"life\" + 0.002*\"american\"'),\n",
            " (1,\n",
            "  '0.008*\"medical\" + 0.007*\"patient\" + 0.005*\"care\" + 0.004*\"public_health\" + '\n",
            "  '0.004*\"mental_health\" + 0.004*\"disease\" + 0.004*\"virus\" + 0.004*\"drug\" + '\n",
            "  '0.004*\"treatment\" + 0.003*\"clinical\"'),\n",
            " (2,\n",
            "  '0.005*\"global\" + 0.004*\"data\" + 0.004*\"technology\" + 0.003*\"company\" + '\n",
            "  '0.003*\"investment\" + 0.003*\"trade\" + 0.003*\"market\" + 0.003*\"sector\" + '\n",
            "  '0.003*\"business\" + 0.003*\"european\"'),\n",
            " (3,\n",
            "  '0.010*\"united_state\" + 0.008*\"security\" + 0.006*\"united\" + 0.006*\"military\" '\n",
            "  '+ 0.005*\"u.s.\" + 0.004*\"russian\" + 0.004*\"china\" + 0.004*\"nuclear\" + '\n",
            "  '0.004*\"strategic\" + 0.004*\"foreign\"'),\n",
            " (4,\n",
            "  '0.005*\"local\" + 0.004*\"rom\" + 0.004*\"programme\" + 0.004*\"community\" + '\n",
            "  '0.004*\"care\" + 0.004*\"public_health\" + 0.004*\"education\" + 0.004*\"hospital\" '\n",
            "  '+ 0.003*\"ministry\" + 0.003*\"().\"'),\n",
            " (5,\n",
            "  '0.009*\"military\" + 0.008*\"percent\" + 0.005*\"force\" + 0.005*\"u.s.\" + '\n",
            "  '0.005*\"program\" + 0.005*\"tax\" + 0.003*\"united_state\" + 0.003*\"federal\" + '\n",
            "  '0.003*\"veteran\" + 0.003*\"million\"'),\n",
            " (6,\n",
            "  '0.005*\"political\" + 0.004*\"right\" + 0.004*\"muslim\" + 0.003*\"minority\" + '\n",
            "  '0.003*\"human_right\" + 0.002*\"law\" + 0.002*\"society\" + 0.002*\"local\" + '\n",
            "  '0.002*\"community\" + 0.002*\"party\"'),\n",
            " (7,\n",
            "  '0.020*\"der\" + 0.019*\"die\" + 0.013*\"und\" + 0.010*\"los\" + 0.010*\"que\" + '\n",
            "  '0.008*\"von\" + 0.008*\"den\" + 0.007*\"para\" + 0.006*\"de\" + 0.006*\"por\"'),\n",
            " (8,\n",
            "  '0.012*\"climate\" + 0.009*\"climate_change\" + 0.008*\"energy\" + 0.006*\"food\" + '\n",
            "  '0.006*\"water\" + 0.006*\"environmental\" + 0.006*\"land\" + 0.003*\"project\" + '\n",
            "  '0.003*\"natural\" + 0.003*\"community\"'),\n",
            " (9,\n",
            "  '0.019*\"alcohol\" + 0.012*\"yes\" + 0.010*\"population\" + 0.008*\"global\" + '\n",
            "  '0.007*\"yes_yes\" + 0.007*\"female\" + 0.007*\"male\" + 0.006*\".–.\" + 0.006*\"(+)\" '\n",
            "  '+ 0.006*\"total\"')]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus_2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcQfxkqqRXsN"
      },
      "source": [
        "### 5. Analyzing LDA model results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEzNfLnzh_I1"
      },
      "source": [
        "Probabilistic topic models, such as LDA, are popular tools for text analysis, providing both a predictive and latent topic representation of the corpus. \n",
        "However, there is a longstanding assumption that the latent space discovered by these models is generally meaningful and useful, and that evaluating such assumptions is challenging due to its unsupervised training process.\n",
        "There is a no-gold standard list of topics to compare against every corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jVW19kjh_I1"
      },
      "source": [
        "Let’s take a look at roughly what approaches are commonly used for the evaluation:\n",
        "\n",
        " **Eye Balling Models**\n",
        ": Top N words\n",
        ": Topics / Documents\n",
        "\n",
        " **Intrinsic Evaluation Metrics**\n",
        ": Capturing model semantics\n",
        ": Topics interpretability\n",
        "\n",
        " **Extrinsic Evaluation Metrics/Evaluation at task**\n",
        ": Is model good at performing predefined tasks, such as classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB0-ycllh_I1"
      },
      "source": [
        "Let’s visualize the topics for interpretability. \n",
        "To do so, we’ll use a popular visualization package, pyLDAvis which is designed to help interactively better understanding\n",
        "and interpreting  individual topics and better understanding the relationships between topics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPpgRFpVh_I1"
      },
      "source": [
        "You can manually select each topic to view its top most frequent and/or “relevant” terms, using different values of the λ parameter. \n",
        "This can help when you’re trying to assign a human interpretable name or “meaning” to each topic.\n",
        "Exploring the Intertopic Distance Plot can help you learn about how topics relate to each other, including potential higher-level structure between groups of topics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s26DrSf9h_I1"
      },
      "source": [
        "https://pyldavis.readthedocs.io/en/latest/modules/API.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9_Z4_aJh_I2"
      },
      "outputs": [],
      "source": [
        "### Visualizing the topics\n",
        "#import graphlab as gl\n",
        "import pyLDAvis\n",
        "import pyLDAvis.graphlab\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "vis=pyLDAvis.gensim.prepare(lda_model, corpus_2, id2word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkcES0fNh_I2"
      },
      "source": [
        "**Topic Coherence** measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjL7fW5YRY-t",
        "outputId": "fb0a7705-63de-4749-f04e-77faea0d709f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score:  0.571362409524663\n"
          ]
        }
      ],
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_docs, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM65jObISowV"
      },
      "source": [
        "### 6. Hyperparameter tuning¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4rlXicqh_I2"
      },
      "source": [
        "Now that we have the baseline coherence score for the default LDA model, let’s perform a series of sensitivity tests to help determine the following model hyperparameters:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXiphLMUh_I2"
      },
      "source": [
        "1. Number of Topics (K)\n",
        "2. Dirichlet hyperparameter alpha: Document-Topic Density\n",
        "3. Dirichlet hyperparameter beta: Word-Topic Density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g05N5TnFh_I3"
      },
      "outputs": [],
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    \n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8dQvcCJh_I3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "grid = {}\n",
        "grid['Validation_Set'] = {}\n",
        "# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 30\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')\n",
        "# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')\n",
        "# Validation sets\n",
        "num_of_docs = len(corpus_2)\n",
        "corpus_sets = [gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
        "               corpus]\n",
        "corpus_title = ['75% Corpus', '100% Corpus']\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "# Can take a long time to run\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=540)\n",
        "    \n",
        "    # iterate through validation corpuses\n",
        "    for i in range(len(corpus_sets)):\n",
        "        # iterate through number of topics\n",
        "        for k in topics_range:\n",
        "            # iterate through alpha values\n",
        "            for a in alpha:\n",
        "                # iterare through beta values\n",
        "                for b in beta:\n",
        "                    # get the coherence score for the given parameters\n",
        "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
        "                                                  k=k, a=a, b=b)\n",
        "                    # Save the model results\n",
        "                    model_results['Validation_Set'].append(corpus_title[i])\n",
        "                    model_results['Topics'].append(k)\n",
        "                    model_results['Alpha'].append(a)\n",
        "                    model_results['Beta'].append(b)\n",
        "                    model_results['Coherence'].append(cv)\n",
        "                    \n",
        "                    pbar.update(1)\n",
        "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
        "    pbar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPsfImW4h_I3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cl1DCx7h_I3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dS1S7ikh_I3"
      },
      "source": [
        "### 7. Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cByfL6ASoA1"
      },
      "outputs": [],
      "source": [
        "# Build LDA model\n",
        "import gensim\n",
        "from gensim import models\n",
        "lda_model_v2 = gensim.models.LdaMulticore(corpus=corpus_2,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=30, #number \n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zot61P7pSoNP",
        "outputId": "57d3767c-a063-4b07-9a3b-b0f24e59abc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score:  0.5759584637009776\n"
          ]
        }
      ],
      "source": [
        "# Compute Coherence Score\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "coherence_model_lda = CoherenceModel(model=lda_model_v2, texts=tokenized_docs, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-xPOoTvH7Z9"
      },
      "outputs": [],
      "source": [
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model=lda_model_v2\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nh1Rb3AH7Z9"
      },
      "outputs": [],
      "source": [
        "model_list, coherence_values = compute_coherence_values(texts=tokenized_docs, dictionary=id2word, start=2, limit=30, step=6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TulTLb4wH7Z9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Show graph\n",
        "import matplotlib.pyplot as plt\n",
        "limit=30; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "64pxXE-SH7Z-",
        "hey62YXFH7aA",
        "wAMUzCDEH7aB",
        "XqhciNAnH7aE",
        "NkmF6WCUH7aE"
      ],
      "name": "LDA.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}